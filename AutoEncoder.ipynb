{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class AutoEncoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AutoEncoder, self).__init__()\n",
    "        self.Encoder = nn.Sequential(\n",
    "            nn.Linear(28*28, 128),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(64, 12),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(12, 2)\n",
    "        )\n",
    "        \n",
    "        self.Decoder = nn.Sequential(\n",
    "            nn.Linear(2, 12),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(12, 64),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(64, 128),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(128, 28*28),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.Encoder(x)\n",
    "        \n",
    "        x = self.Decoder(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "def loss_batch(output, source, target, loss_func, opt=None):\n",
    "    \n",
    "    loss = loss_func(output, target)\n",
    "    \n",
    "    if opt is not None:\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "        \n",
    "    \n",
    "    return loss.item(), len(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "\n",
    "def train(epochs, model, train_dl, valid_dl, loss_func, opt, out_dir, device):\n",
    "    loss_record = 100\n",
    "    for epoch in range(epochs):\n",
    "        \n",
    "        model.train()\n",
    "        for source, target in train_dl:\n",
    "            source, target = source.view(-1,28*28).to(device), target.to(device)\n",
    "            output = model(source)\n",
    "            loss_batch(output, source, source, loss_func, opt)\n",
    "            \n",
    "        \n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            losses = []\n",
    "            nums = []\n",
    "            for source, target in valid_dl:\n",
    "                source, target = source.view(-1,28*28).to(device), target.to(device)\n",
    "                output = model(source)\n",
    "                loss, num = loss_batch(output, source, source, loss_func) \n",
    "                losses.append(loss)\n",
    "                nums.append(num)\n",
    "            if epoch%10==0:\n",
    "                pic = torch.cat((output, source), 0)\n",
    "                pic = pic.view(pic.size(0),1,28,28)\n",
    "                #save_image(pic, './{}/image_{}.png'.format(out_dir, epoch))\n",
    "            \n",
    "            valid_loss = np.sum(np.multiply(losses, nums)) / np.sum(nums)\n",
    "            if valid_loss < loss_record:\n",
    "                #torch.save(model.state_dict(),'./{}/ae_model.pth'.format(out_dir))\n",
    "                #print(\"save model epoch {} {}\".format(epoch, valid_loss))\n",
    "                loss_record = valid_loss\n",
    "            if epoch%10==0:\n",
    "                print(epoch, valid_loss)\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 9625600/9912422 [00:12<00:00, 2317537.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0it [00:00, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/28881 [00:00<?, ?it/s]\u001b[A\n",
      " 57%|█████▋    | 16384/28881 [00:00<00:00, 61438.63it/s]\u001b[A\n",
      "32768it [00:00, 40271.20it/s]                           \u001b[A\n",
      "0it [00:00, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/1648877 [00:00<?, ?it/s]\u001b[A\n",
      "  1%|          | 16384/1648877 [00:00<00:30, 53343.44it/s]\u001b[A\n",
      "  2%|▏         | 40960/1648877 [00:01<00:26, 61532.69it/s]\u001b[A\n",
      "  5%|▍         | 81920/1648877 [00:01<00:20, 75447.20it/s]\u001b[A\n",
      "  8%|▊         | 131072/1648877 [00:01<00:16, 91912.02it/s]\u001b[A\n",
      " 10%|█         | 172032/1648877 [00:01<00:13, 105829.16it/s]\u001b[A\n",
      " 13%|█▎        | 221184/1648877 [00:02<00:11, 122220.40it/s]\u001b[A\n",
      " 16%|█▋        | 270336/1648877 [00:02<00:10, 137102.05it/s]\u001b[A\n",
      " 20%|█▉        | 327680/1648877 [00:02<00:08, 153655.22it/s]\u001b[A\n",
      " 23%|██▎       | 376832/1648877 [00:02<00:07, 164544.60it/s]\u001b[A\n",
      " 26%|██▋       | 434176/1648877 [00:03<00:06, 178695.77it/s]\u001b[A\n",
      " 30%|██▉       | 491520/1648877 [00:03<00:05, 208395.16it/s]\u001b[A\n",
      " 31%|███▏      | 516096/1648877 [00:03<00:05, 216104.46it/s]\u001b[A\n",
      " 34%|███▍      | 557056/1648877 [00:03<00:05, 199823.41it/s]\u001b[A\n",
      " 38%|███▊      | 622592/1648877 [00:03<00:04, 213796.04it/s]\u001b[A\n",
      " 42%|████▏     | 696320/1648877 [00:04<00:04, 230500.34it/s]\u001b[A\n",
      " 47%|████▋     | 770048/1648877 [00:04<00:03, 245013.87it/s]\u001b[A\n",
      " 51%|█████     | 843776/1648877 [00:04<00:03, 261770.09it/s]\u001b[A\n",
      " 56%|█████▌    | 917504/1648877 [00:04<00:02, 302277.67it/s]\u001b[A\n",
      " 58%|█████▊    | 958464/1648877 [00:04<00:02, 300937.51it/s]\u001b[A\n",
      " 61%|██████    | 1007616/1648877 [00:05<00:02, 272499.51it/s]\u001b[A\n",
      " 66%|██████▌   | 1089536/1648877 [00:05<00:01, 318641.96it/s]\u001b[A\n",
      " 69%|██████▊   | 1130496/1648877 [00:05<00:01, 312295.09it/s]\u001b[A\n",
      " 72%|███████▏  | 1187840/1648877 [00:05<00:01, 294366.16it/s]\u001b[A\n",
      " 78%|███████▊  | 1286144/1648877 [00:05<00:01, 340914.93it/s]\u001b[A\n",
      " 80%|████████  | 1327104/1648877 [00:06<00:00, 350561.04it/s]\u001b[A\n",
      " 84%|████████▍ | 1392640/1648877 [00:06<00:00, 394485.76it/s]\u001b[A\n",
      " 87%|████████▋ | 1441792/1648877 [00:06<00:00, 381313.48it/s]\u001b[A\n",
      " 92%|█████████▏| 1515520/1648877 [00:06<00:00, 430037.88it/s]\u001b[A\n",
      " 95%|█████████▍| 1564672/1648877 [00:06<00:00, 410411.90it/s]\u001b[A\n",
      "100%|█████████▉| 1646592/1648877 [00:06<00:00, 465086.47it/s]\u001b[A\n",
      "\n",
      "0it [00:00, ?it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/4542 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "8192it [00:00, 15170.20it/s]            \u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n",
      "Processing...\n",
      "Done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9920512it [00:30, 2317537.74it/s]                             "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torch.utils import data\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "bs = 50\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "\n",
    "data_transform = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "training_data = torchvision.datasets.MNIST(root='./data',train=True,transform=data_transform,download=True)\n",
    "train_ds, valid_ds = data.random_split(training_data,lengths=[50000, 10000])\n",
    "train_dl = DataLoader(train_ds, batch_size=bs, shuffle=True)\n",
    "valid_dl = DataLoader(valid_ds, batch_size=bs*2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 28, 28])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f9fa001a6a0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvIxREBQAADktJREFUeJzt3V2oXeWdx/HvX20vTHuhxqTB+tIpYmbwwk6OMuAokWKNQ8EErdTXDFNzelFhQuZiNEEqTBQZph31Rok0NGqrLSbRUKXxIMM4gUGMQarNSyslEzOGvGihFi+K5j8XZ2c41bOfdXL2y9onz/cDcvbe//2c/e9qfmftvZ+11hOZiaT6nNZ2A5LaYfilShl+qVKGX6qU4ZcqZfilShl+qVKGX6qU4ZcqdcYwXywiPJxQGrDMjJk8r6c9f0Qsi4h9EfFORNzTy++SNFwx22P7I+J04DfAtcBB4HXglszcXRjjnl8asGHs+a8A3snM32Xmn4BngRt6+H2ShqiX8J8HvDvl/sHOY38mIsYjYmdE7OzhtST1WS9f+E331uIzb+szcwOwAXzbL42SXvb8B4Hzp9z/MvBeb+1IGpZewv86cHFEfCUiPg98G9jWn7YkDdqs3/Zn5scRcTewHTgd2JiZv+5bZ5IGatZTfbN6MT/zSwM3lIN8JM1dhl+qlOGXKmX4pUoZfqlShl+qlOGXKmX4pUoZfqlShl+qlOGXKmX4pUoZfqlShl+qlOGXKmX4pUoZfqlShl+qlOGXKmX4pUoZfqlShl+qlOGXKmX4pUoZfqlShl+qlOGXKmX4pUoZfqlSs16iGyAi9gMfAp8AH2fmWD+aqs2yZcuK9XvvvbdYv+qqq7rWtmzZUhwbUV7Qdfny5T2NL73+888/P+uxAB999FGxrrKewt9xTWYe68PvkTREvu2XKtVr+BN4OSLeiIjxfjQkaTh6fdt/ZWa+FxELgImI2JuZr059QuePgn8YpBHT054/M9/r/DwCbAWumOY5GzJzzC8DpdEy6/BHxLyI+OKJ28A3gLf71Zikwerlbf9CYGtnqucM4KeZ+cu+dCVp4CIzh/diEcN7sRGyYsWKYv25554r1pv+PyrNtfcydtDjm8bu3r27WH/22WeL9QceeKBYP1VlZnnDdjjVJ1XK8EuVMvxSpQy/VCnDL1XK8EuVcqqvD8bGygcvvvjii8X6ggULivXNmzcX68eOdT+psnS6L8CNN95YrO/du7dYb7J48eKutXXr1hXHNp1OPG/evGJ9zZo1XWsPP/xwcexc5lSfpCLDL1XK8EuVMvxSpQy/VCnDL1XK8EuVcp6/Dx5//PFi/a677irW9+3bV6xffvnlxfr8+fO71krHAMBoX/6611Ohjx492rW2dOnS4thej29ok/P8kooMv1Qpwy9VyvBLlTL8UqUMv1Qpwy9Vqh+r9Fav6RLUTfWmufam+oEDB4r1uWrr1q3F+hNPPFGsr1q1qmvt6quvLo6dy/P8M+WeX6qU4ZcqZfilShl+qVKGX6qU4ZcqZfilSjXO80fERuCbwJHMvLTz2NnAz4CLgP3AzZn5+8G1OdqaronQVC+djz+TetM5+7Ua5rUq5qKZ7Pl/DCz71GP3AK9k5sXAK537kuaQxvBn5qvAB596+AZgU+f2JqC8tIqkkTPbz/wLM/MQQOdneb0pSSNn4Mf2R8Q4MD7o15F0cma75z8cEYsAOj+PdHtiZm7IzLHMLK9mKWmoZhv+bcDKzu2VwAv9aUfSsDSGPyKeAf4buCQiDkbEd4CHgGsj4rfAtZ37kuaQxs/8mXlLl9LX+9zLnLV9+/Zi/bbbbivWL7zwwmL98OHDxfrKlSu71rZs2VIcO8rX7W/SdE5+03UUaucRflKlDL9UKcMvVcrwS5Uy/FKlDL9UKZfoHoKmpabXr19frF9yySXFemlKa/fu3cWxExMTxXrTVOGOHTuK9V489dRTxfqtt95arJf+t19zzTXFsXP5NGmX6JZUZPilShl+qVKGX6qU4ZcqZfilShl+qVLO84+Ac889t1hvOk5g9erVXWu9HCMAzZe/fv/994v10nEC4+Plq7s1vfauXbuK9euvv75rbS7P4zdxnl9SkeGXKmX4pUoZfqlShl+qlOGXKmX4pUo5z38KOPPMM7vWmo4RWLt2bbE+yOMEej3G4NFHHy3W16xZU6yfqpznl1Rk+KVKGX6pUoZfqpThlypl+KVKGX6pUo1LdEfERuCbwJHMvLTz2P3AKuBo52lrM/OlQTWpstJ8edNceq/1piW+9+7d27W2ZMmS4tgmpesYAFx33XVda0uXLi2OPXr0aLF+KpjJnv/HwLJpHv/3zLys85/Bl+aYxvBn5qvAB0PoRdIQ9fKZ/+6I+FVEbIyIs/rWkaShmG34HwO+ClwGHAJ+0O2JETEeETsjYucsX0vSAMwq/Jl5ODM/yczjwBPAFYXnbsjMscwcm22TkvpvVuGPiEVT7q4A3u5PO5KGZSZTfc8AS4H5EXEQ+D6wNCIuAxLYD3x3gD1KGgDP558DFi9eXKxv3ry5a63X8/FL190HuO+++4r10jx/aR4eYPny5cV6L9f9n5iYKI4tXfN/1Hk+v6Qiwy9VyvBLlTL8UqUMv1Qpwy9Vyqm+EdB0autLL5VPmiwt8d00VXfTTTcV66Ps9ttvL9Y3bdrUtda0tPjYWPmA1AMHDhTrbXKqT1KR4ZcqZfilShl+qVKGX6qU4ZcqZfilSjWez6/BW7VqVbF+zjnnFOulufw777xzVj3NBXv27CnWS8ewNG3T+fPnF+ujPM8/U+75pUoZfqlShl+qlOGXKmX4pUoZfqlShl+qlPP8c0DT5bVffvnlrrWmJbTnsqbjI0rb7d133y2OPRXm8Zu455cqZfilShl+qVKGX6qU4ZcqZfilShl+qVKN8/wRcT7wJPAl4DiwITMfiYizgZ8BFwH7gZsz8/eDa7Vew1xbYZQ0LU2+YsWKYr203Y4ePVoce+zYsWL9VDCTPf/HwD9l5l8CfwN8LyL+CrgHeCUzLwZe6dyXNEc0hj8zD2Xmrs7tD4E9wHnADcCJJVE2AcsH1aSk/jupz/wRcRHwNeA1YGFmHoLJPxDAgn43J2lwZnxsf0R8AdgMrM7MPzQdbz5l3DgwPrv2JA3KjPb8EfE5JoP/k8w8cbXIwxGxqFNfBByZbmxmbsjMscwsr3woaagawx+Tu/gfAXsy84dTStuAlZ3bK4EX+t+epEGZydv+K4E7gLci4s3OY2uBh4CfR8R3gAPAtwbT4qmvadqp6SPW6tWru9aefvrp4thBn/JbWj58/fr1xbHLl5e/Q16woPw105Ej074ZBeCOO+4ojq1BY/gzcwfQ7V/f1/vbjqRh8Qg/qVKGX6qU4ZcqZfilShl+qVKGX6pUDPN00Yio89zUBkuWLCnWX3vttWK9dBzAgw8+WBw7MTFRrDedVtt0+ezSUtcXXHBBcWzTv82m4x/WrFnTtfbII48Ux85lmTmjY+/d80uVMvxSpQy/VCnDL1XK8EuVMvxSpQy/VCnn+eeAdevWFeul8+KPHz9eHHvaaeW//4Mc33Qtga1btxbrTccw7N27t1g/VTnPL6nI8EuVMvxSpQy/VCnDL1XK8EuVMvxSpZznPwU89thjXWtNy1iXrqsPzefU79ixo1gvzdVv3769OLbWefpeOc8vqcjwS5Uy/FKlDL9UKcMvVcrwS5Uy/FKlGuf5I+J84EngS8BxYENmPhIR9wOrgBOLy6/NzJcafpfz/NKAzXSefybhXwQsysxdEfFF4A1gOXAz8MfM/LeZNmX4pcGbafjPmMEvOgQc6tz+MCL2AOf11p6ktp3UZ/6IuAj4GnBi/ai7I+JXEbExIs7qMmY8InZGxM6eOpXUVzM+tj8ivgD8J/BAZm6JiIXAMSCBf2Hyo8E/NPwO3/ZLA9a3z/wAEfE54BfA9sz84TT1i4BfZOalDb/H8EsD1rcTe2JyKdQfAXumBr/zReAJK4C3T7ZJSe2Zybf9fwv8F/AWk1N9AGuBW4DLmHzbvx/4bufLwdLvcs8vDVhf3/b3i+GXBs/z+SUVGX6pUoZfqpThlypl+KVKGX6pUoZfqpThlypl+KVKGX6pUoZfqpThlypl+KVKGX6pUo0X8OyzY8D/TLk/v/PYKBrV3ka1L7C32epnbxfO9IlDPZ//My8esTMzx1proGBUexvVvsDeZqut3nzbL1XK8EuVajv8G1p+/ZJR7W1U+wJ7m61Wemv1M7+k9rS955fUklbCHxHLImJfRLwTEfe00UM3EbE/It6KiDfbXmKsswzakYh4e8pjZ0fERET8tvNz2mXSWurt/oj43862ezMi/q6l3s6PiP+IiD0R8euI+MfO461uu0JfrWy3ob/tj4jTgd8A1wIHgdeBWzJz91Ab6SIi9gNjmdn6nHBEXA38EXjyxGpIEfGvwAeZ+VDnD+dZmfnPI9Lb/Zzkys0D6q3bytJ/T4vbrp8rXvdDG3v+K4B3MvN3mfkn4Fnghhb6GHmZ+SrwwacevgHY1Lm9icl/PEPXpbeRkJmHMnNX5/aHwImVpVvddoW+WtFG+M8D3p1y/yCjteR3Ai9HxBsRMd52M9NYeGJlpM7PBS3382mNKzcP06dWlh6ZbTebFa/7rY3wT7eayChNOVyZmX8NXA98r/P2VjPzGPBVJpdxOwT8oM1mOitLbwZWZ+Yf2uxlqmn6amW7tRH+g8D5U+5/GXivhT6mlZnvdX4eAbYy+TFllBw+sUhq5+eRlvv5f5l5ODM/yczjwBO0uO06K0tvBn6SmVs6D7e+7abrq63t1kb4XwcujoivRMTngW8D21ro4zMiYl7nixgiYh7wDUZv9eFtwMrO7ZXACy328mdGZeXmbitL0/K2G7UVr1s5yKczlfEwcDqwMTMfGHoT04iIv2Bybw+TZzz+tM3eIuIZYCmTZ30dBr4PPA/8HLgAOAB8KzOH/sVbl96WcpIrNw+ot24rS79Gi9uunyte96Ufj/CT6uQRflKlDL9UKcMvVcrwS5Uy/FKlDL9UKcMvVcrwS5X6P/CaoVR2XlN/AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "1654784it [00:25, 465086.47it/s]                             \u001b[A"
     ]
    }
   ],
   "source": [
    "from matplotlib import pyplot\n",
    "print(train_ds[0][0].shape)\n",
    "pyplot.imshow(train_ds[0][0].squeeze(), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AutoEncoder(\n",
      "  (Encoder): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=128, bias=True)\n",
      "    (1): ReLU(inplace)\n",
      "    (2): Linear(in_features=128, out_features=64, bias=True)\n",
      "    (3): ReLU(inplace)\n",
      "    (4): Linear(in_features=64, out_features=12, bias=True)\n",
      "    (5): ReLU(inplace)\n",
      "    (6): Linear(in_features=12, out_features=2, bias=True)\n",
      "  )\n",
      "  (Decoder): Sequential(\n",
      "    (0): Linear(in_features=2, out_features=12, bias=True)\n",
      "    (1): ReLU(inplace)\n",
      "    (2): Linear(in_features=12, out_features=64, bias=True)\n",
      "    (3): ReLU(inplace)\n",
      "    (4): Linear(in_features=64, out_features=128, bias=True)\n",
      "    (5): ReLU(inplace)\n",
      "    (6): Linear(in_features=128, out_features=784, bias=True)\n",
      "    (7): Sigmoid()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as opt\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "lr = 0.001\n",
    "model = AutoEncoder()\n",
    "model.to(device)\n",
    "print(model)\n",
    "criterion = nn.MSELoss()\n",
    "opt = opt.Adam(model.parameters(), lr = lr, weight_decay=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.05251799397170544\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-28935ba126ee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10000\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mout_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'data/mnist_ae_png'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_dl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-5-ddd636da0c55>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(epochs, model, train_dl, valid_dl, loss_func, opt, out_dir, device)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_dl\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m             \u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msource\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/mikamipytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    613\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# same-process loading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    614\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_iter\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 615\u001b[0;31m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    616\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    617\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpin_memory_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/mikamipytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    613\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# same-process loading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    614\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_iter\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 615\u001b[0;31m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    616\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    617\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpin_memory_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/mikamipytorch/lib/python3.6/site-packages/torch/utils/data/dataset.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/mikamipytorch/lib/python3.6/site-packages/torchvision/datasets/mnist.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0;31m# doing this so that it is consistent with all other datasets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;31m# to return a PIL Image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'L'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/mikamipytorch/lib/python3.6/site-packages/PIL/Image.py\u001b[0m in \u001b[0;36mfromarray\u001b[0;34m(obj, mode)\u001b[0m\n\u001b[1;32m   2480\u001b[0m             \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtostring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2481\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2482\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mfrombuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"raw\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrawmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2484\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/mikamipytorch/lib/python3.6/site-packages/PIL/Image.py\u001b[0m in \u001b[0;36mfrombuffer\u001b[0;34m(mode, size, data, decoder_name, *args)\u001b[0m\n\u001b[1;32m   2430\u001b[0m                 \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_buffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2431\u001b[0m                 )\n\u001b[0;32m-> 2432\u001b[0;31m             \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadonly\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2433\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2434\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epochs = 10000\n",
    "out_dir = 'data/mnist_ae_png'\n",
    "train(epochs, model, train_dl, valid_dl, criterion, opt, out_dir, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mikamipytorch",
   "language": "python",
   "name": "mikamipytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
