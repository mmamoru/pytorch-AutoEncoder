{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class AutoEncoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AutoEncoder, self).__init__()\n",
    "        self.Encoder = nn.Sequential(\n",
    "            nn.Linear(28*28, 128),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(64, 12),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(12, 2)\n",
    "        )\n",
    "        \n",
    "        self.Decoder = nn.Sequential(\n",
    "            nn.Linear(2, 12),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(12, 64),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(64, 128),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(128, 28*28),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.Encoder(x)\n",
    "        \n",
    "        x = self.Decoder(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "def loss_batch(output, source, target, loss_func, opt=None):\n",
    "    \n",
    "    loss = loss_func(output, target)\n",
    "    \n",
    "    if opt is not None:\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "        \n",
    "    \n",
    "    return loss.item(), len(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "\n",
    "def train(epochs, model, train_dl, valid_dl, loss_func, opt, out_dir, device):\n",
    "    loss_record = 100\n",
    "    for epoch in range(epochs):\n",
    "        \n",
    "        model.train()\n",
    "        for source, target in train_dl:\n",
    "            source, target = source.view(-1,28*28).to(device), target.to(device)\n",
    "            output = model(source)\n",
    "            loss_batch(output, source, source, loss_func, opt)\n",
    "            \n",
    "        \n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            losses = []\n",
    "            nums = []\n",
    "            for source, target in valid_dl:\n",
    "                source, target = source.view(-1,28*28).to(device), target.to(device)\n",
    "                output = model(source)\n",
    "                loss, num = loss_batch(output, source, source, loss_func) \n",
    "                losses.append(loss)\n",
    "                nums.append(num)\n",
    "            if epoch%10==0:\n",
    "                pic = torch.cat((output, source), 0)\n",
    "                pic = pic.view(pic.size(0),1,28,28)\n",
    "                save_image(pic, './{}/image_{}.png'.format(out_dir, epoch))\n",
    "            \n",
    "            valid_loss = np.sum(np.multiply(losses, nums)) / np.sum(nums)\n",
    "            if valid_loss < loss_record:\n",
    "                torch.save(model.state_dict(),'./{}/ae_model.pth'.format(out_dir))\n",
    "                print(\"save model epoch {} {}\".format(epoch, valid_loss))\n",
    "                loss_record = valid_loss\n",
    "            if epoch%10==0:\n",
    "                print(epoch, valid_loss)\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torch.utils import data\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "bs = 50\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "\n",
    "data_transform = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "training_data = torchvision.datasets.MNIST(root='./data',train=True,transform=data_transform,download=True)\n",
    "train_ds, valid_ds = data.random_split(training_data,lengths=[50000, 10000])\n",
    "train_dl = DataLoader(train_ds, batch_size=bs, shuffle=True)\n",
    "valid_dl = DataLoader(valid_ds, batch_size=bs*2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot\n",
    "print(train_ds[0][0].shape)\n",
    "pyplot.imshow(train_ds[0][0].squeeze(), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as opt\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "lr = 0.001\n",
    "model = AutoEncoder()\n",
    "model.to(device)\n",
    "print(model)\n",
    "criterion = nn.MSELoss()\n",
    "opt = opt.Adam(model.parameters(), lr = lr, weight_decay=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10000\n",
    "out_dir = 'data/mnist_ae_png'\n",
    "train(epochs, model, train_dl, valid_dl, criterion, opt, out_dir, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mikamipytorch",
   "language": "python",
   "name": "mikamipytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
